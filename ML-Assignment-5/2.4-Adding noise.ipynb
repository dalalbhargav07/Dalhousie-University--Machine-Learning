{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 2.4 - \n",
    "**Add label-noise to the training data set and train the two-layer model. To make mislabeled data you can simply shuffle some of the labels. For example, if you want to make 10 percent of the data mislabeled, you can permute/shuffle 10% of the labels. Evaluate the performance of the network with different rates of label noise (10%, 25%, 50%, 75%, 100%) applied. Illustrate your result in a plot. Explain the performance of your network with %100 noise, specifically the difference between the training and test error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding 10% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpimbh2fkh\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_is_chief': True, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D807B0B7B8>, '_save_checkpoints_secs': 600, '_service': None, '_model_dir': 'C:\\\\Users\\\\dalal\\\\AppData\\\\Local\\\\Temp\\\\tmpimbh2fkh', '_session_config': None, '_num_worker_replicas': 1, '_master': '', '_task_type': 'worker'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpimbh2fkh\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3127534, step = 1\n",
      "INFO:tensorflow:global_step/sec: 29.5065\n",
      "INFO:tensorflow:loss = 2.244843, step = 101 (3.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8345\n",
      "INFO:tensorflow:loss = 2.2787418, step = 201 (3.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3318\n",
      "INFO:tensorflow:loss = 2.2528298, step = 301 (3.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1356\n",
      "INFO:tensorflow:loss = 2.2500145, step = 401 (3.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2347\n",
      "INFO:tensorflow:loss = 2.2599857, step = 501 (3.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9251\n",
      "INFO:tensorflow:loss = 2.2729478, step = 601 (3.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2503\n",
      "INFO:tensorflow:loss = 2.2005472, step = 701 (3.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3703\n",
      "INFO:tensorflow:loss = 2.205045, step = 801 (3.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.188\n",
      "INFO:tensorflow:loss = 2.271244, step = 901 (3.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1467\n",
      "INFO:tensorflow:loss = 2.1168659, step = 1001 (3.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2143\n",
      "INFO:tensorflow:loss = 2.022179, step = 1101 (3.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.0974\n",
      "INFO:tensorflow:loss = 2.106863, step = 1201 (3.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8445\n",
      "INFO:tensorflow:loss = 2.040604, step = 1301 (3.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3675\n",
      "INFO:tensorflow:loss = 1.8973465, step = 1401 (3.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4338\n",
      "INFO:tensorflow:loss = 1.8161751, step = 1501 (3.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5249\n",
      "INFO:tensorflow:loss = 1.8943875, step = 1601 (3.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5406\n",
      "INFO:tensorflow:loss = 1.152316, step = 1701 (3.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8323\n",
      "INFO:tensorflow:loss = 1.5480292, step = 1801 (3.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7534\n",
      "INFO:tensorflow:loss = 1.3793913, step = 1901 (3.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3932\n",
      "INFO:tensorflow:loss = 1.018687, step = 2001 (3.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2921\n",
      "INFO:tensorflow:loss = 1.1196301, step = 2101 (3.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5284\n",
      "INFO:tensorflow:loss = 1.3254114, step = 2201 (3.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4429\n",
      "INFO:tensorflow:loss = 0.4735362, step = 2301 (3.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1081\n",
      "INFO:tensorflow:loss = 0.854108, step = 2401 (3.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0944\n",
      "INFO:tensorflow:loss = 1.105236, step = 2501 (3.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3357\n",
      "INFO:tensorflow:loss = 0.97990245, step = 2601 (3.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.491\n",
      "INFO:tensorflow:loss = 2.1213288, step = 2701 (3.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.146\n",
      "INFO:tensorflow:loss = 1.4941511, step = 2801 (3.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2628\n",
      "INFO:tensorflow:loss = 1.3668222, step = 2901 (3.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0953\n",
      "INFO:tensorflow:loss = 0.6006554, step = 3001 (3.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9121\n",
      "INFO:tensorflow:loss = 0.89311934, step = 3101 (3.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1666\n",
      "INFO:tensorflow:loss = 0.79512894, step = 3201 (3.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8061\n",
      "INFO:tensorflow:loss = 0.5725566, step = 3301 (3.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7393\n",
      "INFO:tensorflow:loss = 0.80881006, step = 3401 (3.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6635\n",
      "INFO:tensorflow:loss = 1.0770806, step = 3501 (3.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7593\n",
      "INFO:tensorflow:loss = 0.27850294, step = 3601 (3.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4407\n",
      "INFO:tensorflow:loss = 0.98251927, step = 3701 (3.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4322\n",
      "INFO:tensorflow:loss = 1.2820647, step = 3801 (3.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3815\n",
      "INFO:tensorflow:loss = 1.1582942, step = 3901 (3.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1962\n",
      "INFO:tensorflow:loss = 1.7441126, step = 4001 (3.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1977\n",
      "INFO:tensorflow:loss = 1.8131977, step = 4101 (3.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9563\n",
      "INFO:tensorflow:loss = 0.66786134, step = 4201 (3.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8917\n",
      "INFO:tensorflow:loss = 0.68526524, step = 4301 (3.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9715\n",
      "INFO:tensorflow:loss = 1.1676528, step = 4401 (3.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5476\n",
      "INFO:tensorflow:loss = 0.9743787, step = 4501 (3.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3646\n",
      "INFO:tensorflow:loss = 0.5581915, step = 4601 (3.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2079\n",
      "INFO:tensorflow:loss = 1.1644667, step = 4701 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4564\n",
      "INFO:tensorflow:loss = 0.97518665, step = 4801 (3.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7054\n",
      "INFO:tensorflow:loss = 0.24716134, step = 4901 (4.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6753\n",
      "INFO:tensorflow:loss = 0.3064703, step = 5001 (4.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6966\n",
      "INFO:tensorflow:loss = 0.74241126, step = 5101 (4.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8876\n",
      "INFO:tensorflow:loss = 0.9840461, step = 5201 (4.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8918\n",
      "INFO:tensorflow:loss = 0.8943881, step = 5301 (4.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5729\n",
      "INFO:tensorflow:loss = 1.571663, step = 5401 (4.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6752\n",
      "INFO:tensorflow:loss = 1.5397085, step = 5501 (4.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7838\n",
      "INFO:tensorflow:loss = 1.1242167, step = 5601 (4.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8315\n",
      "INFO:tensorflow:loss = 0.5388657, step = 5701 (4.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2209\n",
      "INFO:tensorflow:loss = 1.0762765, step = 5801 (3.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4195\n",
      "INFO:tensorflow:loss = 1.4913466, step = 5901 (3.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5927\n",
      "INFO:tensorflow:loss = 0.6595125, step = 6001 (3.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9949\n",
      "INFO:tensorflow:loss = 2.1844254, step = 6101 (3.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9498\n",
      "INFO:tensorflow:loss = 1.1386784, step = 6201 (3.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1999\n",
      "INFO:tensorflow:loss = 0.33547172, step = 6301 (3.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2128\n",
      "INFO:tensorflow:loss = 0.3510274, step = 6401 (3.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2459\n",
      "INFO:tensorflow:loss = 0.5757652, step = 6501 (3.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.757\n",
      "INFO:tensorflow:loss = 0.36350933, step = 6601 (3.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7002\n",
      "INFO:tensorflow:loss = 0.62061185, step = 6701 (3.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3176\n",
      "INFO:tensorflow:loss = 0.70973456, step = 6801 (3.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.636\n",
      "INFO:tensorflow:loss = 0.8375031, step = 6901 (3.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.442\n",
      "INFO:tensorflow:loss = 1.4921744, step = 7001 (3.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5646\n",
      "INFO:tensorflow:loss = 0.6286598, step = 7101 (3.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3826\n",
      "INFO:tensorflow:loss = 0.5135499, step = 7201 (3.791 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.8955\n",
      "INFO:tensorflow:loss = 0.546729, step = 7301 (3.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.36\n",
      "INFO:tensorflow:loss = 1.0522172, step = 7401 (3.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3478\n",
      "INFO:tensorflow:loss = 0.7414449, step = 7501 (3.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1204\n",
      "INFO:tensorflow:loss = 1.3533013, step = 7601 (3.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7568\n",
      "INFO:tensorflow:loss = 0.7124368, step = 7701 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3233\n",
      "INFO:tensorflow:loss = 0.7233072, step = 7801 (3.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3155\n",
      "INFO:tensorflow:loss = 0.4077363, step = 7901 (3.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8593\n",
      "INFO:tensorflow:loss = 0.35451382, step = 8001 (4.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0408\n",
      "INFO:tensorflow:loss = 0.3008295, step = 8101 (3.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.909\n",
      "INFO:tensorflow:loss = 0.2568516, step = 8201 (4.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6581\n",
      "INFO:tensorflow:loss = 0.1807261, step = 8301 (4.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0326\n",
      "INFO:tensorflow:loss = 0.9807129, step = 8401 (3.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7565\n",
      "INFO:tensorflow:loss = 0.21862403, step = 8501 (4.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6609\n",
      "INFO:tensorflow:loss = 1.09993, step = 8601 (4.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9933\n",
      "INFO:tensorflow:loss = 0.9917925, step = 8701 (4.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4854\n",
      "INFO:tensorflow:loss = 1.1478165, step = 8801 (4.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8122\n",
      "INFO:tensorflow:loss = 0.6366828, step = 8901 (4.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9265\n",
      "INFO:tensorflow:loss = 0.38693985, step = 9001 (4.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9442\n",
      "INFO:tensorflow:loss = 0.19071083, step = 9101 (4.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.57\n",
      "INFO:tensorflow:loss = 0.974646, step = 9201 (4.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8558\n",
      "INFO:tensorflow:loss = 1.3130492, step = 9301 (4.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7692\n",
      "INFO:tensorflow:loss = 0.64642894, step = 9401 (4.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1224\n",
      "INFO:tensorflow:loss = 0.30707845, step = 9501 (3.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1865\n",
      "INFO:tensorflow:loss = 0.602929, step = 9601 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1748\n",
      "INFO:tensorflow:loss = 0.451135, step = 9701 (3.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8727\n",
      "INFO:tensorflow:loss = 0.9655186, step = 9801 (4.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1873\n",
      "INFO:tensorflow:loss = 0.5640842, step = 9901 (3.970 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpimbh2fkh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.50412273.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-21-23:10:44\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpimbh2fkh\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-21-23:10:55\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9463, global_step = 10000, loss = 0.3041242\n",
      "\n",
      "\n",
      "The accuracy for cnn model with 10% percent noise: 94.63000297546387%\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "num_classes = len(classes)\n",
    "acc =[]\n",
    "\n",
    "def my_cnn_model_fn(features, labels, mode):\n",
    "      \"\"\"Model function for CNN.\"\"\"\n",
    "      # Input Layer\n",
    "      # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "      # MNIST images are 28x28 pixels, and have one color channel\n",
    "      input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "      # Convolutional Layer #1\n",
    "      # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "      # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "      # First max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Convolutional Layer #2\n",
    "      # Computes 64 features using a 5x5 filter.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #2\n",
    "      # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Flatten tensor into a batch of vectors\n",
    "      # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      # Dense Layer\n",
    "      # Densely connected layer with 1024 neurons\n",
    "      # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      # Output Tensor Shape: [batch_size, 1024]\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      # Add dropout operation; 0.6 probability that element will be kept\n",
    "      dropout = tf.layers.dropout(\n",
    "          inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "      # Logits layer\n",
    "      # Input Tensor Shape: [batch_size, 1024]\n",
    "      # Output Tensor Shape: [batch_size, 10]\n",
    "      logits = tf.layers.dense(inputs=dropout, units= num_classes)\n",
    "\n",
    "      predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "     #  Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#  # Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  \n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#                                Adding 10% noise\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "size_noise_label = int(0.1* len(train_labels))\n",
    "noise_label = np.random.choice(len(train_labels),size = size_noise_label,replace=False)\n",
    "train_noise_label = train_labels[noise_label]\n",
    "np.random.shuffle(train_noise_label)\n",
    "train_labels[noise_label] = train_noise_label\n",
    "\n",
    "indices = np.isin(train_labels,classes)\n",
    "sample_train_data = train_data[indices,:]\n",
    "sample_train_labels = train_labels[indices]\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "indices_test = np.isin(eval_labels,classes)\n",
    "sample_eval_data = eval_data[indices_test,:]\n",
    "sample_eval_labels = eval_labels[indices_test]\n",
    "\n",
    "  # Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=my_cnn_model_fn)#, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_train_data},\n",
    "      y=sample_train_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=10000)\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_eval_data},\n",
    "      y=sample_eval_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print('')\n",
    "print('')\n",
    "print('The accuracy for cnn model with 10% percent noise: '+str(eval_results['accuracy']*100)+'%')\n",
    "acc.append(eval_results['accuracy']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding 25% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpp99b3zog\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_is_chief': True, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D809980978>, '_save_checkpoints_secs': 600, '_service': None, '_model_dir': 'C:\\\\Users\\\\dalal\\\\AppData\\\\Local\\\\Temp\\\\tmpp99b3zog', '_session_config': None, '_num_worker_replicas': 1, '_master': '', '_task_type': 'worker'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpp99b3zog\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.272159, step = 1\n",
      "INFO:tensorflow:global_step/sec: 24.7283\n",
      "INFO:tensorflow:loss = 2.259891, step = 101 (4.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9478\n",
      "INFO:tensorflow:loss = 2.2527504, step = 201 (4.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5643\n",
      "INFO:tensorflow:loss = 2.21832, step = 301 (4.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.775\n",
      "INFO:tensorflow:loss = 2.319153, step = 401 (4.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9967\n",
      "INFO:tensorflow:loss = 2.199665, step = 501 (4.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0776\n",
      "INFO:tensorflow:loss = 2.233379, step = 601 (3.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9825\n",
      "INFO:tensorflow:loss = 2.3074107, step = 701 (4.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5251\n",
      "INFO:tensorflow:loss = 2.2657313, step = 801 (3.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5146\n",
      "INFO:tensorflow:loss = 2.2056565, step = 901 (3.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5092\n",
      "INFO:tensorflow:loss = 2.1788044, step = 1001 (3.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7101\n",
      "INFO:tensorflow:loss = 2.0827198, step = 1101 (3.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.705\n",
      "INFO:tensorflow:loss = 2.145125, step = 1201 (3.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6837\n",
      "INFO:tensorflow:loss = 1.9966066, step = 1301 (3.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7494\n",
      "INFO:tensorflow:loss = 2.1811316, step = 1401 (3.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7626\n",
      "INFO:tensorflow:loss = 1.9793524, step = 1501 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6352\n",
      "INFO:tensorflow:loss = 2.0336852, step = 1601 (3.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5076\n",
      "INFO:tensorflow:loss = 1.9266913, step = 1701 (3.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7611\n",
      "INFO:tensorflow:loss = 1.6521038, step = 1801 (3.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7381\n",
      "INFO:tensorflow:loss = 1.6769416, step = 1901 (3.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8701\n",
      "INFO:tensorflow:loss = 1.5727315, step = 2001 (3.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8494\n",
      "INFO:tensorflow:loss = 1.3528271, step = 2101 (3.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9807\n",
      "INFO:tensorflow:loss = 1.826771, step = 2201 (3.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1964\n",
      "INFO:tensorflow:loss = 1.5714786, step = 2301 (3.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3957\n",
      "INFO:tensorflow:loss = 1.6146082, step = 2401 (3.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0228\n",
      "INFO:tensorflow:loss = 1.2242315, step = 2501 (3.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.125\n",
      "INFO:tensorflow:loss = 1.5995551, step = 2601 (3.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0754\n",
      "INFO:tensorflow:loss = 1.4935048, step = 2701 (3.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.933\n",
      "INFO:tensorflow:loss = 1.1838189, step = 2801 (3.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7712\n",
      "INFO:tensorflow:loss = 1.6411976, step = 2901 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8082\n",
      "INFO:tensorflow:loss = 2.2935243, step = 3001 (3.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6642\n",
      "INFO:tensorflow:loss = 1.325396, step = 3101 (3.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6525\n",
      "INFO:tensorflow:loss = 1.0912077, step = 3201 (3.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7428\n",
      "INFO:tensorflow:loss = 1.1374812, step = 3301 (3.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8321\n",
      "INFO:tensorflow:loss = 1.5668293, step = 3401 (3.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7712\n",
      "INFO:tensorflow:loss = 1.8280433, step = 3501 (3.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6785\n",
      "INFO:tensorflow:loss = 2.0122757, step = 3601 (4.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9503\n",
      "INFO:tensorflow:loss = 0.6746746, step = 3701 (4.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9583\n",
      "INFO:tensorflow:loss = 1.4035051, step = 3801 (4.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5513\n",
      "INFO:tensorflow:loss = 2.1056724, step = 3901 (3.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4897\n",
      "INFO:tensorflow:loss = 0.94942427, step = 4001 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9264\n",
      "INFO:tensorflow:loss = 2.2037425, step = 4101 (3.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2819\n",
      "INFO:tensorflow:loss = 1.8772062, step = 4201 (3.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0663\n",
      "INFO:tensorflow:loss = 1.0982186, step = 4301 (3.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.813\n",
      "INFO:tensorflow:loss = 1.3160695, step = 4401 (3.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8599\n",
      "INFO:tensorflow:loss = 1.4209535, step = 4501 (3.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.642\n",
      "INFO:tensorflow:loss = 1.439705, step = 4601 (3.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3805\n",
      "INFO:tensorflow:loss = 0.6595658, step = 4701 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6355\n",
      "INFO:tensorflow:loss = 0.9261507, step = 4801 (3.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6601\n",
      "INFO:tensorflow:loss = 1.8207172, step = 4901 (3.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8459\n",
      "INFO:tensorflow:loss = 1.4604187, step = 5001 (3.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7339\n",
      "INFO:tensorflow:loss = 1.2653564, step = 5101 (3.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8228\n",
      "INFO:tensorflow:loss = 1.2010443, step = 5201 (3.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8845\n",
      "INFO:tensorflow:loss = 1.264456, step = 5301 (3.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7648\n",
      "INFO:tensorflow:loss = 1.2080729, step = 5401 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8046\n",
      "INFO:tensorflow:loss = 2.8088946, step = 5501 (3.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7834\n",
      "INFO:tensorflow:loss = 0.610412, step = 5601 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.678\n",
      "INFO:tensorflow:loss = 1.3576413, step = 5701 (3.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3406\n",
      "INFO:tensorflow:loss = 1.3176403, step = 5801 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7669\n",
      "INFO:tensorflow:loss = 1.5452249, step = 5901 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7706\n",
      "INFO:tensorflow:loss = 2.2123694, step = 6001 (3.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9762\n",
      "INFO:tensorflow:loss = 0.5938164, step = 6101 (3.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7122\n",
      "INFO:tensorflow:loss = 0.93601215, step = 6201 (3.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7871\n",
      "INFO:tensorflow:loss = 1.0764635, step = 6301 (3.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9738\n",
      "INFO:tensorflow:loss = 1.6764685, step = 6401 (3.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7653\n",
      "INFO:tensorflow:loss = 0.7925333, step = 6501 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7681\n",
      "INFO:tensorflow:loss = 2.0459352, step = 6601 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3559\n",
      "INFO:tensorflow:loss = 1.0870521, step = 6701 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3685\n",
      "INFO:tensorflow:loss = 1.6419836, step = 6801 (3.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1456\n",
      "INFO:tensorflow:loss = 0.691253, step = 6901 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8234\n",
      "INFO:tensorflow:loss = 1.2539113, step = 7001 (3.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6245\n",
      "INFO:tensorflow:loss = 1.0944132, step = 7101 (3.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9461\n",
      "INFO:tensorflow:loss = 0.39301413, step = 7201 (3.854 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.3193\n",
      "INFO:tensorflow:loss = 1.1220269, step = 7301 (3.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1633\n",
      "INFO:tensorflow:loss = 0.99292964, step = 7401 (3.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9844\n",
      "INFO:tensorflow:loss = 0.72877604, step = 7501 (3.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9178\n",
      "INFO:tensorflow:loss = 1.5090032, step = 7601 (3.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0093\n",
      "INFO:tensorflow:loss = 1.543918, step = 7701 (3.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7529\n",
      "INFO:tensorflow:loss = 1.1836331, step = 7801 (3.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5541\n",
      "INFO:tensorflow:loss = 1.830684, step = 7901 (3.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7675\n",
      "INFO:tensorflow:loss = 1.0877903, step = 8001 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6997\n",
      "INFO:tensorflow:loss = 1.2346796, step = 8101 (3.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8581\n",
      "INFO:tensorflow:loss = 1.3021696, step = 8201 (3.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7871\n",
      "INFO:tensorflow:loss = 1.4058267, step = 8301 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7231\n",
      "INFO:tensorflow:loss = 1.5741261, step = 8401 (3.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8405\n",
      "INFO:tensorflow:loss = 1.5815427, step = 8501 (3.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7629\n",
      "INFO:tensorflow:loss = 2.3738945, step = 8601 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6565\n",
      "INFO:tensorflow:loss = 0.5401081, step = 8701 (3.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8174\n",
      "INFO:tensorflow:loss = 1.1839514, step = 8801 (3.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6254\n",
      "INFO:tensorflow:loss = 1.3667791, step = 8901 (3.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7783\n",
      "INFO:tensorflow:loss = 1.0540494, step = 9001 (3.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8185\n",
      "INFO:tensorflow:loss = 2.6118677, step = 9101 (3.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7094\n",
      "INFO:tensorflow:loss = 1.8114841, step = 9201 (3.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7879\n",
      "INFO:tensorflow:loss = 1.2370237, step = 9301 (3.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2346\n",
      "INFO:tensorflow:loss = 0.6476964, step = 9401 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6776\n",
      "INFO:tensorflow:loss = 0.84233105, step = 9501 (3.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2002\n",
      "INFO:tensorflow:loss = 1.5631106, step = 9601 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4888\n",
      "INFO:tensorflow:loss = 0.78091496, step = 9701 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5655\n",
      "INFO:tensorflow:loss = 1.034221, step = 9801 (4.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.397\n",
      "INFO:tensorflow:loss = 2.3010526, step = 9901 (3.935 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpp99b3zog\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.5376829.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-21-23:17:29\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpp99b3zog\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-21-23:17:41\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9352, global_step = 10000, loss = 0.5518715\n",
      "\n",
      "\n",
      "The accuracy for cnn model with 25% percent noise: 93.51999759674072%\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def my_cnn_model_fn(features, labels, mode):\n",
    "      \"\"\"Model function for CNN.\"\"\"\n",
    "      # Input Layer\n",
    "      # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "      # MNIST images are 28x28 pixels, and have one color channel\n",
    "      input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "      # Convolutional Layer #1\n",
    "      # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "      # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "      # First max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Convolutional Layer #2\n",
    "      # Computes 64 features using a 5x5 filter.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #2\n",
    "      # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Flatten tensor into a batch of vectors\n",
    "      # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      # Dense Layer\n",
    "      # Densely connected layer with 1024 neurons\n",
    "      # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      # Output Tensor Shape: [batch_size, 1024]\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      # Add dropout operation; 0.6 probability that element will be kept\n",
    "      dropout = tf.layers.dropout(\n",
    "          inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "      # Logits layer\n",
    "      # Input Tensor Shape: [batch_size, 1024]\n",
    "      # Output Tensor Shape: [batch_size, 10]\n",
    "      logits = tf.layers.dense(inputs=dropout, units= num_classes)\n",
    "\n",
    "      predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "     #  Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#  # Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  \n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#                                Adding 25% noise\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "size_noise_label = int(0.25* len(train_labels))\n",
    "noise_label = np.random.choice(len(train_labels),size = size_noise_label,replace=False)\n",
    "train_noise_label = train_labels[noise_label]\n",
    "np.random.shuffle(train_noise_label)\n",
    "train_labels[noise_label] = train_noise_label\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "indices = np.isin(train_labels,classes)\n",
    "sample_train_data = train_data[indices,:]\n",
    "sample_train_labels = train_labels[indices]\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "indices_test = np.isin(eval_labels,classes)\n",
    "sample_eval_data = eval_data[indices_test,:]\n",
    "sample_eval_labels = eval_labels[indices_test]\n",
    "\n",
    "  # Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=my_cnn_model_fn)#, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_train_data},\n",
    "      y=sample_train_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=10000)\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_eval_data},\n",
    "      y=sample_eval_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print('')\n",
    "print('')\n",
    "print('The accuracy for cnn model with 25% percent noise: '+str(eval_results['accuracy']*100)+'%')\n",
    "acc.append(eval_results['accuracy']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added 50% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpir21itga\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_is_chief': True, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D809AA4080>, '_save_checkpoints_secs': 600, '_service': None, '_model_dir': 'C:\\\\Users\\\\dalal\\\\AppData\\\\Local\\\\Temp\\\\tmpir21itga', '_session_config': None, '_num_worker_replicas': 1, '_master': '', '_task_type': 'worker'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpir21itga\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2800984, step = 1\n",
      "INFO:tensorflow:global_step/sec: 24.6791\n",
      "INFO:tensorflow:loss = 2.2992878, step = 101 (4.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5034\n",
      "INFO:tensorflow:loss = 2.3248296, step = 201 (4.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8873\n",
      "INFO:tensorflow:loss = 2.2712917, step = 301 (4.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8277\n",
      "INFO:tensorflow:loss = 2.3025916, step = 401 (4.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9642\n",
      "INFO:tensorflow:loss = 2.2593012, step = 501 (4.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8817\n",
      "INFO:tensorflow:loss = 2.2583747, step = 601 (4.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8459\n",
      "INFO:tensorflow:loss = 2.2294362, step = 701 (4.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9173\n",
      "INFO:tensorflow:loss = 2.2943122, step = 801 (4.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7401\n",
      "INFO:tensorflow:loss = 2.3396156, step = 901 (4.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0061\n",
      "INFO:tensorflow:loss = 2.304954, step = 1001 (4.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9086\n",
      "INFO:tensorflow:loss = 2.2766004, step = 1101 (4.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8202\n",
      "INFO:tensorflow:loss = 2.2606058, step = 1201 (4.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7455\n",
      "INFO:tensorflow:loss = 2.2213829, step = 1301 (4.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9684\n",
      "INFO:tensorflow:loss = 2.3182893, step = 1401 (4.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9133\n",
      "INFO:tensorflow:loss = 2.192397, step = 1501 (4.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3867\n",
      "INFO:tensorflow:loss = 2.1820693, step = 1601 (3.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7752\n",
      "INFO:tensorflow:loss = 2.1816688, step = 1701 (3.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2227\n",
      "INFO:tensorflow:loss = 2.194611, step = 1801 (3.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1334\n",
      "INFO:tensorflow:loss = 2.241929, step = 1901 (3.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5253\n",
      "INFO:tensorflow:loss = 2.2004833, step = 2001 (3.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3266\n",
      "INFO:tensorflow:loss = 2.093184, step = 2101 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8235\n",
      "INFO:tensorflow:loss = 2.1347442, step = 2201 (3.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9242\n",
      "INFO:tensorflow:loss = 2.1756606, step = 2301 (3.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5559\n",
      "INFO:tensorflow:loss = 2.0553932, step = 2401 (3.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4867\n",
      "INFO:tensorflow:loss = 2.293836, step = 2501 (3.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.583\n",
      "INFO:tensorflow:loss = 2.2427263, step = 2601 (4.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.702\n",
      "INFO:tensorflow:loss = 2.3601475, step = 2701 (4.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9366\n",
      "INFO:tensorflow:loss = 2.0427132, step = 2801 (4.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.807\n",
      "INFO:tensorflow:loss = 2.128715, step = 2901 (4.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0617\n",
      "INFO:tensorflow:loss = 1.9701612, step = 3001 (4.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2598\n",
      "INFO:tensorflow:loss = 1.8004843, step = 3101 (4.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7693\n",
      "INFO:tensorflow:loss = 2.1049166, step = 3201 (3.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0078\n",
      "INFO:tensorflow:loss = 2.1539981, step = 3301 (3.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1506\n",
      "INFO:tensorflow:loss = 2.1716485, step = 3401 (4.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.966\n",
      "INFO:tensorflow:loss = 1.4166418, step = 3501 (3.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9476\n",
      "INFO:tensorflow:loss = 1.8442615, step = 3601 (3.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.955\n",
      "INFO:tensorflow:loss = 2.469603, step = 3701 (3.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7833\n",
      "INFO:tensorflow:loss = 2.0803134, step = 3801 (3.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1913\n",
      "INFO:tensorflow:loss = 1.9251362, step = 3901 (3.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9189\n",
      "INFO:tensorflow:loss = 2.512114, step = 4001 (3.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1098\n",
      "INFO:tensorflow:loss = 2.294407, step = 4101 (3.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1634\n",
      "INFO:tensorflow:loss = 1.3888415, step = 4201 (3.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.411\n",
      "INFO:tensorflow:loss = 1.5640501, step = 4301 (3.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1927\n",
      "INFO:tensorflow:loss = 1.8610073, step = 4401 (3.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4182\n",
      "INFO:tensorflow:loss = 1.8943799, step = 4501 (3.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6328\n",
      "INFO:tensorflow:loss = 2.260449, step = 4601 (3.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5153\n",
      "INFO:tensorflow:loss = 1.5611463, step = 4701 (3.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5208\n",
      "INFO:tensorflow:loss = 1.9941629, step = 4801 (3.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6513\n",
      "INFO:tensorflow:loss = 1.9650711, step = 4901 (3.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0594\n",
      "INFO:tensorflow:loss = 1.9107437, step = 5001 (3.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3861\n",
      "INFO:tensorflow:loss = 2.5062585, step = 5101 (3.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.682\n",
      "INFO:tensorflow:loss = 1.9432342, step = 5201 (3.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.332\n",
      "INFO:tensorflow:loss = 1.9803346, step = 5301 (3.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3643\n",
      "INFO:tensorflow:loss = 1.7457441, step = 5401 (3.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1874\n",
      "INFO:tensorflow:loss = 1.7538273, step = 5501 (3.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9518\n",
      "INFO:tensorflow:loss = 2.5434425, step = 5601 (3.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.273\n",
      "INFO:tensorflow:loss = 2.1655018, step = 5701 (3.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2006\n",
      "INFO:tensorflow:loss = 2.216825, step = 5801 (3.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3037\n",
      "INFO:tensorflow:loss = 2.0525422, step = 5901 (3.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.756\n",
      "INFO:tensorflow:loss = 2.261022, step = 6001 (3.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4189\n",
      "INFO:tensorflow:loss = 2.0518157, step = 6101 (3.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1471\n",
      "INFO:tensorflow:loss = 1.6656374, step = 6201 (3.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2742\n",
      "INFO:tensorflow:loss = 1.6997032, step = 6301 (3.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5903\n",
      "INFO:tensorflow:loss = 2.8801713, step = 6401 (3.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3214\n",
      "INFO:tensorflow:loss = 1.9432132, step = 6501 (3.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3128\n",
      "INFO:tensorflow:loss = 1.4313129, step = 6601 (3.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3224\n",
      "INFO:tensorflow:loss = 1.524319, step = 6701 (3.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.471\n",
      "INFO:tensorflow:loss = 1.8114967, step = 6801 (3.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4667\n",
      "INFO:tensorflow:loss = 2.0359185, step = 6901 (3.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4891\n",
      "INFO:tensorflow:loss = 1.9677776, step = 7001 (3.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5226\n",
      "INFO:tensorflow:loss = 1.8041468, step = 7101 (3.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6092\n",
      "INFO:tensorflow:loss = 1.7470863, step = 7201 (3.759 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4583\n",
      "INFO:tensorflow:loss = 1.436131, step = 7301 (3.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4508\n",
      "INFO:tensorflow:loss = 1.5640347, step = 7401 (3.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4085\n",
      "INFO:tensorflow:loss = 1.1637453, step = 7501 (3.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3979\n",
      "INFO:tensorflow:loss = 1.7271674, step = 7601 (3.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5047\n",
      "INFO:tensorflow:loss = 1.9331312, step = 7701 (3.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5295\n",
      "INFO:tensorflow:loss = 2.35938, step = 7801 (3.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5377\n",
      "INFO:tensorflow:loss = 1.6512057, step = 7901 (3.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8505\n",
      "INFO:tensorflow:loss = 1.5347369, step = 8001 (3.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9108\n",
      "INFO:tensorflow:loss = 2.1305926, step = 8101 (3.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7517\n",
      "INFO:tensorflow:loss = 1.5429423, step = 8201 (3.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8502\n",
      "INFO:tensorflow:loss = 1.9781349, step = 8301 (3.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0001\n",
      "INFO:tensorflow:loss = 2.2479491, step = 8401 (3.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8489\n",
      "INFO:tensorflow:loss = 1.599992, step = 8501 (3.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1052\n",
      "INFO:tensorflow:loss = 1.5855503, step = 8601 (3.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6257\n",
      "INFO:tensorflow:loss = 1.8301464, step = 8701 (3.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8317\n",
      "INFO:tensorflow:loss = 1.9208454, step = 8801 (3.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1196\n",
      "INFO:tensorflow:loss = 1.3322773, step = 8901 (3.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1761\n",
      "INFO:tensorflow:loss = 2.5234547, step = 9001 (3.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5796\n",
      "INFO:tensorflow:loss = 1.88427, step = 9101 (3.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.758\n",
      "INFO:tensorflow:loss = 2.2165768, step = 9201 (3.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7465\n",
      "INFO:tensorflow:loss = 1.82199, step = 9301 (3.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7776\n",
      "INFO:tensorflow:loss = 2.6696038, step = 9401 (3.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3134\n",
      "INFO:tensorflow:loss = 1.2655494, step = 9501 (3.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8104\n",
      "INFO:tensorflow:loss = 1.9135273, step = 9601 (3.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3713\n",
      "INFO:tensorflow:loss = 2.1750462, step = 9701 (3.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5711\n",
      "INFO:tensorflow:loss = 2.6663895, step = 9801 (3.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4382\n",
      "INFO:tensorflow:loss = 1.5566727, step = 9901 (3.645 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpir21itga\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4576501.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-21-23:24:07\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpir21itga\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-21-23:24:17\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9073, global_step = 10000, loss = 0.9753429\n",
      "\n",
      "\n",
      "The accuracy for cnn model with 50% percent noise: 90.72999954223633%\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def my_cnn_model_fn(features, labels, mode):\n",
    "      \"\"\"Model function for CNN.\"\"\"\n",
    "      # Input Layer\n",
    "      # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "      # MNIST images are 28x28 pixels, and have one color channel\n",
    "      input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "      # Convolutional Layer #1\n",
    "      # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "      # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "      # First max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Convolutional Layer #2\n",
    "      # Computes 64 features using a 5x5 filter.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #2\n",
    "      # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Flatten tensor into a batch of vectors\n",
    "      # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      # Dense Layer\n",
    "      # Densely connected layer with 1024 neurons\n",
    "      # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      # Output Tensor Shape: [batch_size, 1024]\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      # Add dropout operation; 0.6 probability that element will be kept\n",
    "      dropout = tf.layers.dropout(\n",
    "          inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "      # Logits layer\n",
    "      # Input Tensor Shape: [batch_size, 1024]\n",
    "      # Output Tensor Shape: [batch_size, 10]\n",
    "      logits = tf.layers.dense(inputs=dropout, units= num_classes)\n",
    "\n",
    "      predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "     #  Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#  # Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  \n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#                                Adding 50% noise\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "size_noise_label = int(0.5* len(train_labels))\n",
    "noise_label = np.random.choice(len(train_labels),size = size_noise_label,replace=False)\n",
    "train_noise_label = train_labels[noise_label]\n",
    "np.random.shuffle(train_noise_label)\n",
    "train_labels[noise_label] = train_noise_label\n",
    "\n",
    "indices = np.isin(train_labels,classes)\n",
    "sample_train_data = train_data[indices,:]\n",
    "sample_train_labels = train_labels[indices]\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "indices_test = np.isin(eval_labels,classes)\n",
    "sample_eval_data = eval_data[indices_test,:]\n",
    "sample_eval_labels = eval_labels[indices_test]\n",
    "\n",
    "  # Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=my_cnn_model_fn)#, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_train_data},\n",
    "      y=sample_train_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=10000)\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_eval_data},\n",
    "      y=sample_eval_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print('')\n",
    "print('')\n",
    "print('The accuracy for cnn model with 50% percent noise: '+str(eval_results['accuracy']*100)+'%')\n",
    "acc.append(eval_results['accuracy']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding 75%noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpu0efj4ec\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_is_chief': True, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D809D79358>, '_save_checkpoints_secs': 600, '_service': None, '_model_dir': 'C:\\\\Users\\\\dalal\\\\AppData\\\\Local\\\\Temp\\\\tmpu0efj4ec', '_session_config': None, '_num_worker_replicas': 1, '_master': '', '_task_type': 'worker'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpu0efj4ec\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3078198, step = 1\n",
      "INFO:tensorflow:global_step/sec: 28.2429\n",
      "INFO:tensorflow:loss = 2.3100004, step = 101 (3.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.218\n",
      "INFO:tensorflow:loss = 2.3065262, step = 201 (3.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0894\n",
      "INFO:tensorflow:loss = 2.321589, step = 301 (3.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6608\n",
      "INFO:tensorflow:loss = 2.2949703, step = 401 (4.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2781\n",
      "INFO:tensorflow:loss = 2.2640274, step = 501 (3.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.35\n",
      "INFO:tensorflow:loss = 2.3189692, step = 601 (3.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5803\n",
      "INFO:tensorflow:loss = 2.2915738, step = 701 (3.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3801\n",
      "INFO:tensorflow:loss = 2.3010526, step = 801 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5164\n",
      "INFO:tensorflow:loss = 2.3174622, step = 901 (3.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2888\n",
      "INFO:tensorflow:loss = 2.2975056, step = 1001 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0889\n",
      "INFO:tensorflow:loss = 2.3164973, step = 1101 (3.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0359\n",
      "INFO:tensorflow:loss = 2.2731237, step = 1201 (4.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.148\n",
      "INFO:tensorflow:loss = 2.2695389, step = 1301 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1107\n",
      "INFO:tensorflow:loss = 2.3067524, step = 1401 (3.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4875\n",
      "INFO:tensorflow:loss = 2.294133, step = 1501 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3365\n",
      "INFO:tensorflow:loss = 2.2974067, step = 1601 (3.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1806\n",
      "INFO:tensorflow:loss = 2.2732415, step = 1701 (3.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3812\n",
      "INFO:tensorflow:loss = 2.2791123, step = 1801 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.236\n",
      "INFO:tensorflow:loss = 2.29102, step = 1901 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1009\n",
      "INFO:tensorflow:loss = 2.295134, step = 2001 (4.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.36\n",
      "INFO:tensorflow:loss = 2.2954373, step = 2101 (4.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2515\n",
      "INFO:tensorflow:loss = 2.3003812, step = 2201 (3.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5922\n",
      "INFO:tensorflow:loss = 2.309647, step = 2301 (4.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0231\n",
      "INFO:tensorflow:loss = 2.304003, step = 2401 (4.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5125\n",
      "INFO:tensorflow:loss = 2.2867074, step = 2501 (4.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7026\n",
      "INFO:tensorflow:loss = 2.253873, step = 2601 (4.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9711\n",
      "INFO:tensorflow:loss = 2.2796116, step = 2701 (4.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2308\n",
      "INFO:tensorflow:loss = 2.2593396, step = 2801 (3.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6658\n",
      "INFO:tensorflow:loss = 2.241246, step = 2901 (3.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8288\n",
      "INFO:tensorflow:loss = 2.2311864, step = 3001 (3.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6157\n",
      "INFO:tensorflow:loss = 2.242782, step = 3101 (3.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7806\n",
      "INFO:tensorflow:loss = 2.3310766, step = 3201 (3.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7646\n",
      "INFO:tensorflow:loss = 2.2520661, step = 3301 (3.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6176\n",
      "INFO:tensorflow:loss = 2.2991328, step = 3401 (3.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6062\n",
      "INFO:tensorflow:loss = 2.2994573, step = 3501 (3.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9595\n",
      "INFO:tensorflow:loss = 2.2952125, step = 3601 (3.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.377\n",
      "INFO:tensorflow:loss = 2.3098605, step = 3701 (3.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4209\n",
      "INFO:tensorflow:loss = 2.2420204, step = 3801 (3.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.777\n",
      "INFO:tensorflow:loss = 2.2749512, step = 3901 (3.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8999\n",
      "INFO:tensorflow:loss = 2.3144805, step = 4001 (3.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2225\n",
      "INFO:tensorflow:loss = 2.2413628, step = 4101 (3.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0688\n",
      "INFO:tensorflow:loss = 2.2413645, step = 4201 (3.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0266\n",
      "INFO:tensorflow:loss = 2.2425332, step = 4301 (3.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6853\n",
      "INFO:tensorflow:loss = 2.2302735, step = 4401 (3.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6594\n",
      "INFO:tensorflow:loss = 2.3252153, step = 4501 (3.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1466\n",
      "INFO:tensorflow:loss = 2.2926993, step = 4601 (3.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2433\n",
      "INFO:tensorflow:loss = 2.198743, step = 4701 (3.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0509\n",
      "INFO:tensorflow:loss = 2.2116063, step = 4801 (3.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3333\n",
      "INFO:tensorflow:loss = 2.2671154, step = 4901 (3.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9472\n",
      "INFO:tensorflow:loss = 2.1967006, step = 5001 (3.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1331\n",
      "INFO:tensorflow:loss = 2.3721585, step = 5101 (3.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.962\n",
      "INFO:tensorflow:loss = 2.1641643, step = 5201 (3.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6662\n",
      "INFO:tensorflow:loss = 2.2562714, step = 5301 (4.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7257\n",
      "INFO:tensorflow:loss = 2.2619977, step = 5401 (4.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6056\n",
      "INFO:tensorflow:loss = 2.199021, step = 5501 (4.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0419\n",
      "INFO:tensorflow:loss = 2.2642722, step = 5601 (4.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0642\n",
      "INFO:tensorflow:loss = 2.3798707, step = 5701 (4.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6421\n",
      "INFO:tensorflow:loss = 2.195869, step = 5801 (4.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5436\n",
      "INFO:tensorflow:loss = 2.2770875, step = 5901 (4.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8665\n",
      "INFO:tensorflow:loss = 2.2380168, step = 6001 (4.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5051\n",
      "INFO:tensorflow:loss = 2.2883096, step = 6101 (3.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5238\n",
      "INFO:tensorflow:loss = 2.3886056, step = 6201 (3.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5683\n",
      "INFO:tensorflow:loss = 2.075256, step = 6301 (3.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4761\n",
      "INFO:tensorflow:loss = 2.0789657, step = 6401 (3.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.514\n",
      "INFO:tensorflow:loss = 2.1469226, step = 6501 (3.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5554\n",
      "INFO:tensorflow:loss = 2.3043218, step = 6601 (3.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6576\n",
      "INFO:tensorflow:loss = 2.230174, step = 6701 (4.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6381\n",
      "INFO:tensorflow:loss = 2.2351422, step = 6801 (3.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.416\n",
      "INFO:tensorflow:loss = 2.1644642, step = 6901 (3.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4522\n",
      "INFO:tensorflow:loss = 2.229796, step = 7001 (3.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.513\n",
      "INFO:tensorflow:loss = 2.2299912, step = 7101 (3.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6158\n",
      "INFO:tensorflow:loss = 2.0734067, step = 7201 (3.621 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.544\n",
      "INFO:tensorflow:loss = 2.4606643, step = 7301 (3.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6932\n",
      "INFO:tensorflow:loss = 2.2105343, step = 7401 (3.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.622\n",
      "INFO:tensorflow:loss = 2.2097824, step = 7501 (3.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3536\n",
      "INFO:tensorflow:loss = 2.1397614, step = 7601 (3.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6587\n",
      "INFO:tensorflow:loss = 2.2444768, step = 7701 (3.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3266\n",
      "INFO:tensorflow:loss = 2.2153203, step = 7801 (3.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.185\n",
      "INFO:tensorflow:loss = 2.3033135, step = 7901 (3.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4\n",
      "INFO:tensorflow:loss = 2.3624218, step = 8001 (3.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5936\n",
      "INFO:tensorflow:loss = 2.350522, step = 8101 (3.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6498\n",
      "INFO:tensorflow:loss = 2.1544342, step = 8201 (3.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4792\n",
      "INFO:tensorflow:loss = 2.258239, step = 8301 (3.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5945\n",
      "INFO:tensorflow:loss = 2.0931797, step = 8401 (3.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6936\n",
      "INFO:tensorflow:loss = 2.4382067, step = 8501 (3.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.827\n",
      "INFO:tensorflow:loss = 2.147435, step = 8601 (3.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6004\n",
      "INFO:tensorflow:loss = 2.278932, step = 8701 (3.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.579\n",
      "INFO:tensorflow:loss = 2.2984982, step = 8801 (3.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5853\n",
      "INFO:tensorflow:loss = 2.2555578, step = 8901 (3.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5769\n",
      "INFO:tensorflow:loss = 2.1490254, step = 9001 (3.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7242\n",
      "INFO:tensorflow:loss = 2.2512689, step = 9101 (3.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6929\n",
      "INFO:tensorflow:loss = 2.1034775, step = 9201 (3.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6607\n",
      "INFO:tensorflow:loss = 2.1064754, step = 9301 (3.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.18\n",
      "INFO:tensorflow:loss = 2.2838058, step = 9401 (3.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3552\n",
      "INFO:tensorflow:loss = 2.4935577, step = 9501 (3.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6686\n",
      "INFO:tensorflow:loss = 2.28571, step = 9601 (3.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4804\n",
      "INFO:tensorflow:loss = 2.3294005, step = 9701 (3.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5208\n",
      "INFO:tensorflow:loss = 2.2163987, step = 9801 (3.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.421\n",
      "INFO:tensorflow:loss = 2.120072, step = 9901 (3.647 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpu0efj4ec\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.1668034.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-21-23:30:46\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\dalal\\AppData\\Local\\Temp\\tmpu0efj4ec\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-21-23:30:56\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.8295, global_step = 10000, loss = 1.6844592\n",
      "\n",
      "\n",
      "The accuracy for cnn model with 75% percent noise: 82.95000195503235%\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def my_cnn_model_fn(features, labels, mode):\n",
    "      \"\"\"Model function for CNN.\"\"\"\n",
    "      # Input Layer\n",
    "      # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "      # MNIST images are 28x28 pixels, and have one color channel\n",
    "      input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "      # Convolutional Layer #1\n",
    "      # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "      # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "      # First max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Convolutional Layer #2\n",
    "      # Computes 64 features using a 5x5 filter.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #2\n",
    "      # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Flatten tensor into a batch of vectors\n",
    "      # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      # Dense Layer\n",
    "      # Densely connected layer with 1024 neurons\n",
    "      # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      # Output Tensor Shape: [batch_size, 1024]\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      # Add dropout operation; 0.6 probability that element will be kept\n",
    "      dropout = tf.layers.dropout(\n",
    "          inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "      # Logits layer\n",
    "      # Input Tensor Shape: [batch_size, 1024]\n",
    "      # Output Tensor Shape: [batch_size, 10]\n",
    "      logits = tf.layers.dense(inputs=dropout, units= num_classes)\n",
    "\n",
    "      predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "     #  Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#  # Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  \n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#                                Adding 75% noise\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "size_noise_label = int(0.75* len(train_labels))\n",
    "noise_label = np.random.choice(len(train_labels),size = size_noise_label,replace=False)\n",
    "train_noise_label = train_labels[noise_label]\n",
    "np.random.shuffle(train_noise_label)\n",
    "train_labels[noise_label] = train_noise_label\n",
    "\n",
    "indices = np.isin(train_labels,classes)\n",
    "sample_train_data = train_data[indices,:]\n",
    "sample_train_labels = train_labels[indices]\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "indices_test = np.isin(eval_labels,classes)\n",
    "sample_eval_data = eval_data[indices_test,:]\n",
    "sample_eval_labels = eval_labels[indices_test]\n",
    "\n",
    "  # Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=my_cnn_model_fn)#, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_train_data},\n",
    "      y=sample_train_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=10000)\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_eval_data},\n",
    "      y=sample_eval_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print('')\n",
    "print('')\n",
    "print('The accuracy for cnn model with 75% percent noise: '+str(eval_results['accuracy']*100)+'%')\n",
    "acc.append(eval_results['accuracy']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding 100% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\dalal\\AppData\\Local\\Temp\\tmp7ppn8dkc\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_is_chief': True, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D809AA4400>, '_save_checkpoints_secs': 600, '_service': None, '_model_dir': 'C:\\\\Users\\\\dalal\\\\AppData\\\\Local\\\\Temp\\\\tmp7ppn8dkc', '_session_config': None, '_num_worker_replicas': 1, '_master': '', '_task_type': 'worker'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmp7ppn8dkc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3134155, step = 1\n",
      "INFO:tensorflow:global_step/sec: 28.5158\n",
      "INFO:tensorflow:loss = 2.2857966, step = 101 (3.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1807\n",
      "INFO:tensorflow:loss = 2.355067, step = 201 (4.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7137\n",
      "INFO:tensorflow:loss = 2.3354526, step = 301 (4.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1732\n",
      "INFO:tensorflow:loss = 2.2699952, step = 401 (3.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7942\n",
      "INFO:tensorflow:loss = 2.3041294, step = 501 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4047\n",
      "INFO:tensorflow:loss = 2.3045852, step = 601 (3.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3325\n",
      "INFO:tensorflow:loss = 2.2859724, step = 701 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3271\n",
      "INFO:tensorflow:loss = 2.302437, step = 801 (3.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5551\n",
      "INFO:tensorflow:loss = 2.3093038, step = 901 (3.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4226\n",
      "INFO:tensorflow:loss = 2.280401, step = 1001 (3.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4259\n",
      "INFO:tensorflow:loss = 2.3066144, step = 1101 (3.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4356\n",
      "INFO:tensorflow:loss = 2.2796001, step = 1201 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2329\n",
      "INFO:tensorflow:loss = 2.2758203, step = 1301 (3.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1983\n",
      "INFO:tensorflow:loss = 2.3081334, step = 1401 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3713\n",
      "INFO:tensorflow:loss = 2.3092723, step = 1501 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2071\n",
      "INFO:tensorflow:loss = 2.308765, step = 1601 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3552\n",
      "INFO:tensorflow:loss = 2.282166, step = 1701 (3.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3847\n",
      "INFO:tensorflow:loss = 2.2693582, step = 1801 (3.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2259\n",
      "INFO:tensorflow:loss = 2.3167825, step = 1901 (3.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3963\n",
      "INFO:tensorflow:loss = 2.3450265, step = 2001 (3.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2964\n",
      "INFO:tensorflow:loss = 2.3218246, step = 2101 (3.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3107\n",
      "INFO:tensorflow:loss = 2.2838848, step = 2201 (3.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1768\n",
      "INFO:tensorflow:loss = 2.301519, step = 2301 (3.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3674\n",
      "INFO:tensorflow:loss = 2.2901187, step = 2401 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2115\n",
      "INFO:tensorflow:loss = 2.2615466, step = 2501 (3.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2776\n",
      "INFO:tensorflow:loss = 2.3252733, step = 2601 (3.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4146\n",
      "INFO:tensorflow:loss = 2.305128, step = 2701 (3.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4743\n",
      "INFO:tensorflow:loss = 2.2922215, step = 2801 (3.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4019\n",
      "INFO:tensorflow:loss = 2.3175855, step = 2901 (3.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0617\n",
      "INFO:tensorflow:loss = 2.276354, step = 3001 (3.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7889\n",
      "INFO:tensorflow:loss = 2.2863986, step = 3101 (3.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2988\n",
      "INFO:tensorflow:loss = 2.3280454, step = 3201 (3.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3453\n",
      "INFO:tensorflow:loss = 2.3064752, step = 3301 (3.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2153\n",
      "INFO:tensorflow:loss = 2.284824, step = 3401 (3.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9761\n",
      "INFO:tensorflow:loss = 2.3459954, step = 3501 (3.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4764\n",
      "INFO:tensorflow:loss = 2.2816787, step = 3601 (3.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3811\n",
      "INFO:tensorflow:loss = 2.2884724, step = 3701 (3.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1635\n",
      "INFO:tensorflow:loss = 2.3061352, step = 3801 (3.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6061\n",
      "INFO:tensorflow:loss = 2.2988238, step = 3901 (3.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.299\n",
      "INFO:tensorflow:loss = 2.3316894, step = 4001 (3.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4441\n",
      "INFO:tensorflow:loss = 2.291923, step = 4101 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1971\n",
      "INFO:tensorflow:loss = 2.3201835, step = 4201 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2239\n",
      "INFO:tensorflow:loss = 2.2894073, step = 4301 (3.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1804\n",
      "INFO:tensorflow:loss = 2.3097758, step = 4401 (3.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3177\n",
      "INFO:tensorflow:loss = 2.2846282, step = 4501 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1914\n",
      "INFO:tensorflow:loss = 2.2809896, step = 4601 (3.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2851\n",
      "INFO:tensorflow:loss = 2.284211, step = 4701 (3.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4164\n",
      "INFO:tensorflow:loss = 2.3478568, step = 4801 (3.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4306\n",
      "INFO:tensorflow:loss = 2.312531, step = 4901 (3.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3544\n",
      "INFO:tensorflow:loss = 2.2623515, step = 5001 (3.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3152\n",
      "INFO:tensorflow:loss = 2.3012457, step = 5101 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4867\n",
      "INFO:tensorflow:loss = 2.2948775, step = 5201 (3.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4955\n",
      "INFO:tensorflow:loss = 2.3233976, step = 5301 (3.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4985\n",
      "INFO:tensorflow:loss = 2.29852, step = 5401 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3737\n",
      "INFO:tensorflow:loss = 2.2695527, step = 5501 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6715\n",
      "INFO:tensorflow:loss = 2.301265, step = 5601 (3.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0848\n",
      "INFO:tensorflow:loss = 2.302707, step = 5701 (3.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2095\n",
      "INFO:tensorflow:loss = 2.3055577, step = 5801 (3.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2519\n",
      "INFO:tensorflow:loss = 2.2998955, step = 5901 (3.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6217\n",
      "INFO:tensorflow:loss = 2.2753525, step = 6001 (3.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.455\n",
      "INFO:tensorflow:loss = 2.2647643, step = 6101 (3.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5409\n",
      "INFO:tensorflow:loss = 2.3382623, step = 6201 (3.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1001\n",
      "INFO:tensorflow:loss = 2.3108387, step = 6301 (3.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5335\n",
      "INFO:tensorflow:loss = 2.3076446, step = 6401 (3.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5157\n",
      "INFO:tensorflow:loss = 2.298586, step = 6501 (3.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1457\n",
      "INFO:tensorflow:loss = 2.3144562, step = 6601 (3.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6736\n",
      "INFO:tensorflow:loss = 2.2972336, step = 6701 (3.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0028\n",
      "INFO:tensorflow:loss = 2.2949579, step = 6801 (3.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7854\n",
      "INFO:tensorflow:loss = 2.2914586, step = 6901 (4.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.74\n",
      "INFO:tensorflow:loss = 2.3407092, step = 7001 (3.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9716\n",
      "INFO:tensorflow:loss = 2.3182151, step = 7101 (4.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4511\n",
      "INFO:tensorflow:loss = 2.2930627, step = 7201 (4.090 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6947\n",
      "INFO:tensorflow:loss = 2.2957258, step = 7301 (3.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2503\n",
      "INFO:tensorflow:loss = 2.3383718, step = 7401 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9921\n",
      "INFO:tensorflow:loss = 2.308017, step = 7501 (4.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3913\n",
      "INFO:tensorflow:loss = 2.2797408, step = 7601 (4.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5905\n",
      "INFO:tensorflow:loss = 2.3003824, step = 7701 (4.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7581\n",
      "INFO:tensorflow:loss = 2.2897515, step = 7801 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6552\n",
      "INFO:tensorflow:loss = 2.306308, step = 7901 (3.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9601\n",
      "INFO:tensorflow:loss = 2.290594, step = 8001 (4.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9206\n",
      "INFO:tensorflow:loss = 2.3026338, step = 8101 (4.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3675\n",
      "INFO:tensorflow:loss = 2.2971244, step = 8201 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8801\n",
      "INFO:tensorflow:loss = 2.3101819, step = 8301 (4.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5781\n",
      "INFO:tensorflow:loss = 2.3043156, step = 8401 (4.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3163\n",
      "INFO:tensorflow:loss = 2.3115354, step = 8501 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5084\n",
      "INFO:tensorflow:loss = 2.3025315, step = 8601 (3.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1766\n",
      "INFO:tensorflow:loss = 2.3322496, step = 8701 (3.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.268\n",
      "INFO:tensorflow:loss = 2.30915, step = 8801 (3.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7747\n",
      "INFO:tensorflow:loss = 2.3112974, step = 8901 (3.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7725\n",
      "INFO:tensorflow:loss = 2.318447, step = 9001 (3.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3884\n",
      "INFO:tensorflow:loss = 2.3110752, step = 9101 (3.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1223\n",
      "INFO:tensorflow:loss = 2.3083565, step = 9201 (3.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1463\n",
      "INFO:tensorflow:loss = 2.2822824, step = 9301 (3.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5558\n",
      "INFO:tensorflow:loss = 2.2725072, step = 9401 (3.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6183\n",
      "INFO:tensorflow:loss = 2.319981, step = 9501 (3.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7629\n",
      "INFO:tensorflow:loss = 2.3225524, step = 9601 (3.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3814\n",
      "INFO:tensorflow:loss = 2.2725387, step = 9701 (3.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7614\n",
      "INFO:tensorflow:loss = 2.3276677, step = 9801 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8211\n",
      "INFO:tensorflow:loss = 2.3200169, step = 9901 (3.872 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\dalal\\AppData\\Local\\Temp\\tmp7ppn8dkc\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3253033.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-21-23:37:31\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\dalal\\AppData\\Local\\Temp\\tmp7ppn8dkc\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-21-23:37:41\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.1101, global_step = 10000, loss = 2.3010728\n",
      "\n",
      "\n",
      "The accuracy for cnn model with 75% percent noise: 11.010000109672546%\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def my_cnn_model_fn(features, labels, mode):\n",
    "      \"\"\"Model function for CNN.\"\"\"\n",
    "      # Input Layer\n",
    "      # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "      # MNIST images are 28x28 pixels, and have one color channel\n",
    "      input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "      # Convolutional Layer #1\n",
    "      # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "      # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      conv1 = tf.layers.conv2d(\n",
    "          inputs=input_layer,\n",
    "          filters=32,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #1\n",
    "      # First max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Convolutional Layer #2\n",
    "      # Computes 64 features using a 5x5 filter.\n",
    "      # Padding is added to preserve width and height.\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "      # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "      # Pooling Layer #2\n",
    "      # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "      # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "      # Flatten tensor into a batch of vectors\n",
    "      # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "      # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "      # Dense Layer\n",
    "      # Densely connected layer with 1024 neurons\n",
    "      # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "      # Output Tensor Shape: [batch_size, 1024]\n",
    "      dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "      # Add dropout operation; 0.6 probability that element will be kept\n",
    "      dropout = tf.layers.dropout(\n",
    "          inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "      # Logits layer\n",
    "      # Input Tensor Shape: [batch_size, 1024]\n",
    "      # Output Tensor Shape: [batch_size, 10]\n",
    "      logits = tf.layers.dense(inputs=dropout, units= num_classes)\n",
    "\n",
    "      predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "      if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "      # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "      loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "      # Configure the Training Op (for TRAIN mode)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "     #  Add evaluation metrics (for EVAL mode)\n",
    "      eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#  # Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  \n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#                                Adding 100% noise\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "size_noise_label = int(1* len(train_labels))\n",
    "noise_label = np.random.choice(len(train_labels),size = size_noise_label,replace=False)\n",
    "train_noise_label = train_labels[noise_label]\n",
    "np.random.shuffle(train_noise_label)\n",
    "train_labels[noise_label] = train_noise_label\n",
    "\n",
    "indices = np.isin(train_labels,classes)\n",
    "sample_train_data = train_data[indices,:]\n",
    "sample_train_labels = train_labels[indices]\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "indices_test = np.isin(eval_labels,classes)\n",
    "sample_eval_data = eval_data[indices_test,:]\n",
    "sample_eval_labels = eval_labels[indices_test]\n",
    "\n",
    "  # Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=my_cnn_model_fn)#, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_train_data},\n",
    "      y=sample_train_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=10000)\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": sample_eval_data},\n",
    "      y=sample_eval_labels,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print('')\n",
    "print('')\n",
    "print('The accuracy for cnn model with 100% percent noise: '+str(eval_results['accuracy']*100)+'%')\n",
    "acc.append(eval_results['accuracy']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the model with 10% noisy label 94.63000297546387\n",
      "The accuracy for the model with 25% noisy label 93.51999759674072\n",
      "The accuracy for the model with 50% noisy label 90.72999954223633\n",
      "The accuracy for the model with 75% noisy label 82.95000195503235\n",
      "The accuracy for the model with 100% noisy label 11.010000109672546\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy for the model with 10% noisy label', acc[0])\n",
    "print('The accuracy for the model with 25% noisy label', acc[1])\n",
    "print('The accuracy for the model with 50% noisy label', acc[2])\n",
    "print('The accuracy for the model with 75% noisy label', acc[3])\n",
    "print('The accuracy for the model with 100% noisy label', acc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy vs Noise Added')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d809ab1470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(acc)\n",
    "plt.title('Accuracy vs Noise Added')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is depicting clearly that the cnn model is robust when train with massive noisy labels. This suggest that the cnn model with noisy labels also can give us the good quality of prediction. However, still the prediction would be better if provided the clean labels. It is also observed that if the batch size is increased the model, it will perform better with noisy labels. But by changing the batch size, the learning rate also required to be changed.[1] Thus, by tuning the hyer parameters, the noisy data can also be useful in doing prediction fairly upto some extent.\n",
    "\n",
    "**References:**  <br  \\>\n",
    "[1] Anon. Deep Learning is Robust to Massive Label Noise. Retrieved March 22, 2018 from https://www.bing.com/cr?IG=D63A23596755480A82433558FBB65AD8&CID=2EF48864BDD463CF274083DEBC7B62CB&rd=1&h=CEKguXIc-cfFBOvig2HqKDNNjxWViFQcwXEYSIZHFk0&v=1&r=https://arxiv.org/pdf/1705.10694.pdf&p=DevEx,5062.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
